{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfzv8raGkME8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import multivariate_normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JNuNpOQ2Z37",
        "outputId": "29d073b6-ccac-41ef-b9f4-fac8b6b6ebd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSz1X2Kc7bDG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "orig_dir = os.getcwd()\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "from mfcc import MFCC\n",
        "os.chdir(orig_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9E9ujSwOuDz"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "    mfccs = MFCC(file_path)\n",
        "    return mfccs.T\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/SPEECH_A6/sre_new_dataset'\n",
        "speaker_dirs = os.listdir(data_dir)\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for label, speaker_dir in enumerate(speaker_dirs):\n",
        "    speaker_path = os.path.join(data_dir, speaker_dir)\n",
        "    for wav_file in os.listdir(speaker_path):\n",
        "        file_path = os.path.join(speaker_path, wav_file)\n",
        "        features.append(extract_features(file_path))\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32TFUIKmQap_",
        "outputId": "bfc9f5e8-671f-47ff-cf13-53c80036e251"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3597, 42)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDy8zu6Ruxfa"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKQ7_QUyBx30",
        "outputId": "7f3d9178-ea07-4c34-8d5a-30bb51985c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "700 560 140\n",
            "(3597, 42)\n"
          ]
        }
      ],
      "source": [
        "print(len(features), len(train_features), len(test_features))\n",
        "print(features[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zom2MIVIbO3",
        "outputId": "455842ff-d2eb-46e2-8d30-48f808c497b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2614154, 42)\n"
          ]
        }
      ],
      "source": [
        "ubm_features = np.concatenate(train_features)\n",
        "print(ubm_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdzVCDMsIC5l"
      },
      "outputs": [],
      "source": [
        "class KMeans():\n",
        "    def __init__(self, n_clusters, max_iters = 20, threshold = 1000):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iters = max_iters\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False), :]\n",
        "        prev_centroids = self.centroids.copy()\n",
        "\n",
        "        for i in range(self.max_iters):\n",
        "            distances = self._get_distances(X)\n",
        "            labels = np.argmin(distances, axis=1)\n",
        "\n",
        "            for j in range(self.n_clusters):\n",
        "                self.centroids[j] = np.mean(X[labels == j], axis=0)\n",
        "\n",
        "            new_centroids = self.centroids\n",
        "            centroid_distance = np.linalg.norm(new_centroids - prev_centroids)\n",
        "            print(centroid_distance)\n",
        "            if centroid_distance < self.threshold:\n",
        "              print(f'Kmeans converged in {i+1} iterations')\n",
        "              break\n",
        "            prev_centroids = self.centroids.copy()\n",
        "        self.labels = labels\n",
        "\n",
        "    def _get_distances(self, X):\n",
        "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
        "\n",
        "        for i in range(self.n_clusters):\n",
        "            distances[:, i] = np.linalg.norm(X - self.centroids[i], axis=1)\n",
        "\n",
        "        return distances\n",
        "\n",
        "    def get_means(self):\n",
        "      return self.centroids\n",
        "\n",
        "    def get_labels(self):\n",
        "      return self.labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaqbUdSAnm_R",
        "outputId": "23751ff3-37d3-48d1-e381-7d1591e121dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "212472.54303980473\n",
            "3341689.70959963\n",
            "2690190.8278467082\n",
            "260879.36447235712\n",
            "53941.38250697448\n",
            "84124.7616146722\n",
            "544010.3099038219\n",
            "2184195.0290925214\n",
            "1029239.1552596877\n",
            "600469.8273902357\n",
            "346687.1657076922\n",
            "207075.9534210261\n",
            "107771.20970379224\n",
            "85785.52979051265\n",
            "60270.486612271445\n",
            "40821.5374832921\n",
            "24260.620926993328\n",
            "12427.97937530196\n",
            "11542.117986756832\n",
            "10535.852182134015\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(100)\n",
        "kmeans.fit(ubm_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GqTDq38yoSO3",
        "outputId": "1e351a14-9d63-458b-cea2-722fce031fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2614154, 42)\n",
            "(2614154,)\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n"
          ]
        }
      ],
      "source": [
        "data = ubm_features\n",
        "labels = kmeans.get_labels()\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(np.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ozuEXTzlnSYZ"
      },
      "outputs": [],
      "source": [
        "data = ubm_features\n",
        "labels = kmeans.get_labels()\n",
        "n_clusters = len(np.unique(labels))\n",
        "n_features = data.shape[1]\n",
        "\n",
        "cluster_means = {}\n",
        "for label in np.unique(labels):\n",
        "    cluster_data = data[labels == label]\n",
        "    cluster_means[label] = np.mean(cluster_data, axis=0)\n",
        "\n",
        "covariances = np.zeros((n_clusters, n_features, n_features))\n",
        "counts = np.zeros(n_clusters)\n",
        "for label in np.unique(labels):\n",
        "    covariances[label] = np.zeros((data.shape[1], data.shape[1]))\n",
        "    counts[label] = 0\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "    label = labels[i]\n",
        "    x = data[i, :]\n",
        "    mean = cluster_means[label]\n",
        "    covariances[label] += np.outer(x - mean, x - mean)\n",
        "    counts[label] += 1\n",
        "\n",
        "for label in np.unique(labels):\n",
        "    covariances[label] /= counts[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dm6Vto5SdyRQ",
        "outputId": "bd5bde47-5bec-4fc3-e747-485a3f0a8f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  4483.   3267.  65225.  19992. 182328.   2173.   8133.  10308.   1944.\n",
            "   9385.  17314.   4241.   5851.  20192.  21446.  10873.   5229.   5732.\n",
            "   3587.   9363. 191718.  65072. 168760.  13349.  10910.  13229.   9818.\n",
            "  13312.  10956.  10190.   2959.  38096.   6482.   6684.  10276.  22655.\n",
            "    304.  45139.  21147.   7700.   6908.  76750.   3989.  18957.  20272.\n",
            "  35102.   9597.  21974.   6266.   6245.   8916.   5572.   5194.  24467.\n",
            "   3737.   3226. 107224.   2319.  10331.   6369.   2690.   6511. 106551.\n",
            " 180425.  13328.   6877.    243.  40889.  20010.   6953.  11325.  28041.\n",
            "   7409.  12179. 126319.   6328.   8297.  18130.   9112.   5549.  14044.\n",
            "  19443.   6447.  30577.  51552.  16949.  20128.   8576.  16053.   3448.\n",
            "   7249. 120059.   9311.  58567. 108936.  17691.   4406.   7428.   5719.\n",
            "   7168.]\n"
          ]
        }
      ],
      "source": [
        "labels = kmeans.get_labels()\n",
        "count_list = np.zeros(100)\n",
        "for i in range(len(labels)):\n",
        "  count_list[labels[i]] += 1\n",
        "\n",
        "print(count_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_PnqrI2HTsnp"
      },
      "outputs": [],
      "source": [
        "def diag_det(matrix):\n",
        "  d = matrix.shape[0]\n",
        "  log_prod = 0\n",
        "  log_list = []\n",
        "  for i in range(d):\n",
        "    log_list.append(np.log(matrix[i,i]+1e-6))\n",
        "  log_list = np.nan_to_num(log_list, nan=0)\n",
        "  log_prod = np.sum(log_list)\n",
        "  prod = np.exp(log_prod)\n",
        "  return prod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2zG2fnKRUH-Y"
      },
      "outputs": [],
      "source": [
        "def diag_inv(matrix):\n",
        "  inverse_matrix = []\n",
        "  for i in range(len(matrix)):\n",
        "    row = []\n",
        "    for j in range(len(matrix)):\n",
        "      if i == j:\n",
        "        row.append(1 / (matrix[i][j]+1e-6))\n",
        "      else:\n",
        "        row.append(0)\n",
        "    inverse_matrix.append(row)\n",
        "  return np.array(inverse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OawedDXGAbv6"
      },
      "outputs": [],
      "source": [
        "# def gaussian_pdf(x, mu, sigma):\n",
        "#     d = mu.shape[0]\n",
        "#     inv_sigma = diag_inv(sigma)\n",
        "#     det_sigma = diag_det(sigma)\n",
        "#     norm_const = 1 / ((2*np.pi)**(d/2) * np.sqrt(det_sigma))\n",
        "#     diff = x - mu\n",
        "#     exponent = -0.5 * np.sum(np.dot(diff, inv_sigma) * diff, axis=1)\n",
        "#     pdf = norm_const * np.exp(exponent)\n",
        "#     return pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwWYjFRY8lB_"
      },
      "outputs": [],
      "source": [
        "def gaussian_pdf(x, mu, sigma):\n",
        "    d = mu.shape[0]\n",
        "    inv_sigma = diag_inv(sigma)\n",
        "    det_sigma = diag_det(sigma)\n",
        "    norm_const = 1 / ((2*np.pi)**(d/2) * np.sqrt(det_sigma))\n",
        "    diff = x - mu\n",
        "    exponent = -0.5 * np.sum(np.dot(diff, inv_sigma) * diff, axis=1)\n",
        "    pdf = norm_const * np.exp(exponent)\n",
        "    return pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X63g5ZEKRP79"
      },
      "outputs": [],
      "source": [
        "n_components = 20\n",
        "init_means = kmeans.get_means().copy()\n",
        "init_covariances = covariances\n",
        "init_weights = np.ones(n_components) / n_components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBYP9mdW5K8Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class GMM():\n",
        "    def __init__(self, n_components, max_iter = 10, tol=1e-4):\n",
        "        self.n_components = n_components\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "\n",
        "    def _init_params(self, X, means, covariances, weights):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.means_ = means.copy()\n",
        "        self.covariances_ = covariances.copy()\n",
        "        self.weights_ = weights.copy()\n",
        "\n",
        "    def _estimate_posterior(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        likelihoods = np.zeros((n_samples, self.n_components))\n",
        "        for j in range(self.n_components):\n",
        "          likelihoods[:, j] = self.weights_[j] * gaussian_pdf(X, self.means_[j], self.covariances_[j])\n",
        "        posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n",
        "        posteriors = np.nan_to_num(posteriors)\n",
        "        scores = likelihoods.sum(axis = 1)\n",
        "        scores[scores == 0] = 1e-150\n",
        "        log_likelihoods = np.log(scores)\n",
        "        total_log_likelihood = np.sum(log_likelihoods)\n",
        "        return total_log_likelihood, posteriors\n",
        "\n",
        "\n",
        "    def fit(self, X):\n",
        "        self._init_params(X, init_means, init_covariances, init_weights)\n",
        "        prev_log_likelihood = -np.inf\n",
        "        for i in range(self.max_iter):\n",
        "            # E-step\n",
        "            log_likelihood, posteriors = self._estimate_posterior(X)\n",
        "            Ns = np.sum(posteriors, axis= 0)\n",
        "\n",
        "            # M-step\n",
        "            for j in range(self.n_components):\n",
        "                self.means_[j] = np.sum(posteriors[:, j].reshape(-1,1)*X, axis=0)/Ns[j]\n",
        "                diff = X - self.means_[j]\n",
        "                self.covariances_[j] = np.sum(posteriors[:, j, np.newaxis] * diff **2, axis=0) / Ns[j]\n",
        "                self.weights_[j] = Ns[j]/np.sum(Ns)\n",
        "\n",
        "            if abs(log_likelihood - prev_log_likelihood) < self.tol:\n",
        "              break\n",
        "\n",
        "            if i > 0:\n",
        "              print(f'Change in Log Likelihood: {log_likelihood - prev_log_likelihood}')\n",
        "\n",
        "            prev_log_likelihood = log_likelihood.copy()\n",
        "\n",
        "    def predict(self, X):\n",
        "      likelihood, posteriors = self._estimate_posterior(X)\n",
        "      return posteriors\n",
        "\n",
        "    def score(self, X):\n",
        "      likelihood, _ = self._estimate_posterior(X)\n",
        "      return likelihood\n",
        "\n",
        "    def get_means(self):\n",
        "        return self.means_\n",
        "\n",
        "    def get_covariances(self):\n",
        "        return self.covariances_\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "559Itk4U9D7T",
        "outputId": "0ece8c33-05ab-4845-de72-b6a1d2a5b9de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-1364c02f19e8>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Change in Log Likelihood: 1506742.7330776155\n",
            "Change in Log Likelihood: 514593.8558846712\n",
            "Change in Log Likelihood: 382591.7030055523\n",
            "Change in Log Likelihood: 309045.28001469374\n",
            "Change in Log Likelihood: 249095.39559558034\n",
            "Change in Log Likelihood: 195015.1250398457\n",
            "Change in Log Likelihood: 153036.85146540403\n",
            "Change in Log Likelihood: 121529.21259361506\n",
            "Change in Log Likelihood: 98105.82557073236\n"
          ]
        }
      ],
      "source": [
        "ubm_gmm = GMM(20)\n",
        "ubm_gmm.fit(ubm_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPtjz1x2Sgkj",
        "outputId": "ae4faf01-2126-4352-cf5d-fe0483f141fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11985.29407075 59989.86518117 32495.79800211 22477.51989604\n",
            " 32877.83231724 18757.56881645 16271.6320281  19983.07137618\n",
            " 10331.23240304 44968.42193793  9020.00922832 63277.90818516\n",
            " 11874.88886629 18547.92069901   165.30175731 25614.43641456\n",
            " 30789.20623175 21101.2543835   6662.08968178 64047.74852324]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-1364c02f19e8>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n"
          ]
        }
      ],
      "source": [
        "posterior_prob = ubm_gmm.predict(ubm_features)\n",
        "eff_points = posterior_prob.sum(axis=0)\n",
        "print(eff_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDSHEIoFrYTF"
      },
      "outputs": [],
      "source": [
        "def get_super_vector(ubm_gmm, test_utterance):\n",
        "    post_probs = ubm_gmm.predict(test_utterance)\n",
        "    N_k = post_probs.sum(axis=0)\n",
        "    relevance_factor = 50*np.mean(N_k)\n",
        "    means = (post_probs.T @ test_utterance)/(N_k[:, np.newaxis])\n",
        "    means = np.nan_to_num(means, nan=0)\n",
        "    alpha_k = [[i/(i+relevance_factor)] for i in N_k]\n",
        "    alpha_k = np.array(alpha_k)\n",
        "    ubm_means = ubm_gmm.get_means()\n",
        "    new_means = ubm_means + alpha_k*(means - ubm_means)\n",
        "    supervector = new_means.reshape(-1)\n",
        "    return supervector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIT9a7DbQA6H",
        "outputId": "b32fc639-1ec2-49d1-d723-6221e424ce24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([14, 15,  5, ..., 11, 11, 19])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjzRooRUr0j_",
        "outputId": "ded9a43e-75ea-4e50-a22d-f7b935686173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112\n"
          ]
        }
      ],
      "source": [
        "print(len(train_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijCdSyi1PdX-",
        "outputId": "5e9b1d40-01ab-470e-be46-a39ec0c338f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-1364c02f19e8>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n"
          ]
        }
      ],
      "source": [
        "train_super_vectors=[]\n",
        "for i, x in enumerate(train_features):\n",
        "  train_super_vectors.append(get_super_vector(ubm_gmm,x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oVyv0gERAyg",
        "outputId": "033e4b9b-fd1e-4117-e6d0-1618b5c87ec3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_super_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqWW0xgJ8lRI",
        "outputId": "a6d3a402-1e38-411d-c334-91d2e8e0916a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.87496002]\n",
            " [0.98444459]\n",
            " [0.96950505]\n",
            " [0.93450043]\n",
            " [0.95832867]\n",
            " [0.94487253]\n",
            " [0.83300874]\n",
            " [0.92694066]\n",
            " [0.80550365]\n",
            " [0.94206619]\n",
            " [0.69186397]\n",
            " [0.98396422]\n",
            " [0.8491131 ]\n",
            " [0.9463902 ]\n",
            " [0.12769354]\n",
            " [0.96017255]\n",
            " [0.95727447]\n",
            " [0.86516626]\n",
            " [0.55345311]\n",
            " [0.98467166]]\n",
            "[[0.5293148 ]\n",
            " [0.86936453]\n",
            " [0.41496166]\n",
            " [0.64236062]\n",
            " [0.91598916]\n",
            " [0.6304223 ]\n",
            " [0.98453287]\n",
            " [0.39115117]\n",
            " [0.95237997]\n",
            " [0.99297935]\n",
            " [0.63629318]\n",
            " [0.94777049]\n",
            " [0.55351077]\n",
            " [0.74174475]\n",
            " [0.08455945]\n",
            " [0.3157024 ]\n",
            " [0.92970438]\n",
            " [0.98752255]\n",
            " [0.94287967]\n",
            " [0.94718947]]\n",
            "[[0.91189723]\n",
            " [0.97016197]\n",
            " [0.95556418]\n",
            " [0.93649963]\n",
            " [0.96380245]\n",
            " [0.93238151]\n",
            " [0.91768417]\n",
            " [0.93493913]\n",
            " [0.91589904]\n",
            " [0.97557326]\n",
            " [0.90909354]\n",
            " [0.98014368]\n",
            " [0.91492998]\n",
            " [0.94333271]\n",
            " [0.15420862]\n",
            " [0.94880738]\n",
            " [0.96199411]\n",
            " [0.93844873]\n",
            " [0.88631888]\n",
            " [0.98050111]]\n",
            "[[0.35494533]\n",
            " [0.8661611 ]\n",
            " [0.2060638 ]\n",
            " [0.49411148]\n",
            " [0.91110039]\n",
            " [0.39333461]\n",
            " [0.98525822]\n",
            " [0.19995232]\n",
            " [0.94994202]\n",
            " [0.99315027]\n",
            " [0.51289015]\n",
            " [0.94334232]\n",
            " [0.31854508]\n",
            " [0.58307537]\n",
            " [0.11578634]\n",
            " [0.33092654]\n",
            " [0.92079022]\n",
            " [0.98827751]\n",
            " [0.9446493 ]\n",
            " [0.94318419]]\n",
            "[[0.92766205]\n",
            " [0.97483438]\n",
            " [0.9682067 ]\n",
            " [0.95968986]\n",
            " [0.9700704 ]\n",
            " [0.95102262]\n",
            " [0.66081649]\n",
            " [0.94703829]\n",
            " [0.80588996]\n",
            " [0.91137696]\n",
            " [0.87354518]\n",
            " [0.98278581]\n",
            " [0.92555584]\n",
            " [0.94904346]\n",
            " [0.07483931]\n",
            " [0.96174842]\n",
            " [0.96581331]\n",
            " [0.74455007]\n",
            " [0.55804555]\n",
            " [0.98226154]]\n",
            "[[0.9044206 ]\n",
            " [0.98478881]\n",
            " [0.97390388]\n",
            " [0.9529639 ]\n",
            " [0.95480791]\n",
            " [0.93283038]\n",
            " [0.38190272]\n",
            " [0.96232247]\n",
            " [0.52220901]\n",
            " [0.78211508]\n",
            " [0.87076969]\n",
            " [0.98380251]\n",
            " [0.91699188]\n",
            " [0.93251682]\n",
            " [0.1060807 ]\n",
            " [0.96510312]\n",
            " [0.94929473]\n",
            " [0.3389383 ]\n",
            " [0.23750396]\n",
            " [0.98430073]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-1364c02f19e8>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.89708892]\n",
            " [0.99395806]\n",
            " [0.9691702 ]\n",
            " [0.9322387 ]\n",
            " [0.93712462]\n",
            " [0.90080598]\n",
            " [0.05206757]\n",
            " [0.94418053]\n",
            " [0.57795305]\n",
            " [0.55980561]\n",
            " [0.8581453 ]\n",
            " [0.97556398]\n",
            " [0.87419445]\n",
            " [0.89812021]\n",
            " [0.04444278]\n",
            " [0.95661614]\n",
            " [0.92971113]\n",
            " [0.00547287]\n",
            " [0.41116272]\n",
            " [0.97573902]]\n",
            "[[0.74333704]\n",
            " [0.93526746]\n",
            " [0.78475152]\n",
            " [0.81906375]\n",
            " [0.95697028]\n",
            " [0.86151282]\n",
            " [0.97689743]\n",
            " [0.65698453]\n",
            " [0.95639848]\n",
            " [0.99031574]\n",
            " [0.7859742 ]\n",
            " [0.96819905]\n",
            " [0.77037519]\n",
            " [0.9018186 ]\n",
            " [0.09558517]\n",
            " [0.80516738]\n",
            " [0.95800946]\n",
            " [0.98164   ]\n",
            " [0.94274068]\n",
            " [0.97141604]]\n",
            "[[0.78940912]\n",
            " [0.9555058 ]\n",
            " [0.82907945]\n",
            " [0.86530722]\n",
            " [0.94973689]\n",
            " [0.89259277]\n",
            " [0.97099142]\n",
            " [0.74419268]\n",
            " [0.94747634]\n",
            " [0.99101121]\n",
            " [0.73176384]\n",
            " [0.97498028]\n",
            " [0.80877937]\n",
            " [0.91246619]\n",
            " [0.11357183]\n",
            " [0.83875148]\n",
            " [0.94766829]\n",
            " [0.9779819 ]\n",
            " [0.91900043]\n",
            " [0.97302674]]\n",
            "[[0.92046812]\n",
            " [0.96984307]\n",
            " [0.97078156]\n",
            " [0.95975831]\n",
            " [0.97256104]\n",
            " [0.94451255]\n",
            " [0.73189583]\n",
            " [0.95775312]\n",
            " [0.85100878]\n",
            " [0.88164427]\n",
            " [0.91939093]\n",
            " [0.98075561]\n",
            " [0.925935  ]\n",
            " [0.94161282]\n",
            " [0.21539475]\n",
            " [0.96042212]\n",
            " [0.97050812]\n",
            " [0.77096588]\n",
            " [0.78602273]\n",
            " [0.98137044]]\n",
            "[[0.90261097]\n",
            " [0.96991343]\n",
            " [0.93891358]\n",
            " [0.92987645]\n",
            " [0.96753631]\n",
            " [0.93389055]\n",
            " [0.92107515]\n",
            " [0.87224842]\n",
            " [0.91255923]\n",
            " [0.97523399]\n",
            " [0.92031259]\n",
            " [0.98270537]\n",
            " [0.89059952]\n",
            " [0.95264716]\n",
            " [0.18919294]\n",
            " [0.93188816]\n",
            " [0.96463414]\n",
            " [0.94463431]\n",
            " [0.86687258]\n",
            " [0.98252601]]\n",
            "[[0.89576551]\n",
            " [0.9769438 ]\n",
            " [0.96999557]\n",
            " [0.95955285]\n",
            " [0.9687087 ]\n",
            " [0.94623778]\n",
            " [0.74901481]\n",
            " [0.94896028]\n",
            " [0.7825725 ]\n",
            " [0.90385199]\n",
            " [0.90419926]\n",
            " [0.98232701]\n",
            " [0.91683233]\n",
            " [0.94489774]\n",
            " [0.07472389]\n",
            " [0.9605326 ]\n",
            " [0.96622605]\n",
            " [0.78858891]\n",
            " [0.74211235]\n",
            " [0.98276416]]\n",
            "[[0.91364682]\n",
            " [0.97805925]\n",
            " [0.97202433]\n",
            " [0.96081433]\n",
            " [0.96389611]\n",
            " [0.94911819]\n",
            " [0.43081241]\n",
            " [0.95547175]\n",
            " [0.82993838]\n",
            " [0.86662045]\n",
            " [0.86034677]\n",
            " [0.98301992]\n",
            " [0.93235755]\n",
            " [0.94166379]\n",
            " [0.07604563]\n",
            " [0.96396946]\n",
            " [0.95978304]\n",
            " [0.50569982]\n",
            " [0.69809832]\n",
            " [0.98322661]]\n",
            "[[0.89501687]\n",
            " [0.97671615]\n",
            " [0.9660359 ]\n",
            " [0.95020021]\n",
            " [0.96498162]\n",
            " [0.94932329]\n",
            " [0.87932668]\n",
            " [0.9463507 ]\n",
            " [0.84830584]\n",
            " [0.96335891]\n",
            " [0.77209424]\n",
            " [0.98181218]\n",
            " [0.88161569]\n",
            " [0.94184024]\n",
            " [0.08920607]\n",
            " [0.96160217]\n",
            " [0.96167178]\n",
            " [0.91208494]\n",
            " [0.65747842]\n",
            " [0.98225914]]\n",
            "[[0.77603664]\n",
            " [0.93592709]\n",
            " [0.79386591]\n",
            " [0.83515296]\n",
            " [0.95803418]\n",
            " [0.882837  ]\n",
            " [0.97223277]\n",
            " [0.66195111]\n",
            " [0.94870563]\n",
            " [0.99060269]\n",
            " [0.79460139]\n",
            " [0.97382534]\n",
            " [0.78269131]\n",
            " [0.91749127]\n",
            " [0.09538193]\n",
            " [0.79557979]\n",
            " [0.96112763]\n",
            " [0.97946356]\n",
            " [0.92306065]\n",
            " [0.97406429]]\n",
            "[[0.91297622]\n",
            " [0.97824881]\n",
            " [0.96630727]\n",
            " [0.95227442]\n",
            " [0.96436074]\n",
            " [0.94672874]\n",
            " [0.71304181]\n",
            " [0.94184415]\n",
            " [0.86822501]\n",
            " [0.92158924]\n",
            " [0.89458164]\n",
            " [0.98337249]\n",
            " [0.92473254]\n",
            " [0.94475616]\n",
            " [0.19752124]\n",
            " [0.96020227]\n",
            " [0.96230564]\n",
            " [0.79694106]\n",
            " [0.81412451]\n",
            " [0.98328503]]\n",
            "[[0.90448626]\n",
            " [0.98325412]\n",
            " [0.97301717]\n",
            " [0.94807458]\n",
            " [0.96034013]\n",
            " [0.9507911 ]\n",
            " [0.33346288]\n",
            " [0.94878796]\n",
            " [0.76191805]\n",
            " [0.88754506]\n",
            " [0.73578652]\n",
            " [0.98423258]\n",
            " [0.89953714]\n",
            " [0.94187412]\n",
            " [0.09645915]\n",
            " [0.96579971]\n",
            " [0.95624342]\n",
            " [0.32972882]\n",
            " [0.21393592]\n",
            " [0.98425464]]\n",
            "[[0.94548286]\n",
            " [0.96991462]\n",
            " [0.97019684]\n",
            " [0.96529838]\n",
            " [0.96748871]\n",
            " [0.95235944]\n",
            " [0.52995435]\n",
            " [0.96301568]\n",
            " [0.84003187]\n",
            " [0.85135478]\n",
            " [0.92500679]\n",
            " [0.98020939]\n",
            " [0.93254763]\n",
            " [0.94298352]\n",
            " [0.06176927]\n",
            " [0.96331424]\n",
            " [0.96568076]\n",
            " [0.56967185]\n",
            " [0.71483278]\n",
            " [0.98100069]]\n",
            "[[0.93911116]\n",
            " [0.97293616]\n",
            " [0.97026114]\n",
            " [0.95828985]\n",
            " [0.96839342]\n",
            " [0.95148548]\n",
            " [0.63422217]\n",
            " [0.95170326]\n",
            " [0.87439456]\n",
            " [0.88868542]\n",
            " [0.93038962]\n",
            " [0.98096586]\n",
            " [0.92406854]\n",
            " [0.94823357]\n",
            " [0.14547928]\n",
            " [0.96126455]\n",
            " [0.96460411]\n",
            " [0.70936328]\n",
            " [0.78219693]\n",
            " [0.9813884 ]]\n",
            "[[0.91430468]\n",
            " [0.97526053]\n",
            " [0.96678365]\n",
            " [0.95828025]\n",
            " [0.96887291]\n",
            " [0.95308142]\n",
            " [0.71239122]\n",
            " [0.95275524]\n",
            " [0.82916343]\n",
            " [0.92141128]\n",
            " [0.8200194 ]\n",
            " [0.98287855]\n",
            " [0.91135533]\n",
            " [0.94866832]\n",
            " [0.07747934]\n",
            " [0.9602368 ]\n",
            " [0.96691605]\n",
            " [0.7589053 ]\n",
            " [0.62643893]\n",
            " [0.9830981 ]]\n"
          ]
        }
      ],
      "source": [
        "def map_adaptation(ubm_gmm, speaker_features, relevance_factor=5, eps=1e-8):\n",
        "\n",
        "    post_probs = ubm_gmm.predict(speaker_features)\n",
        "    N_k = post_probs.sum(axis=0)\n",
        "    relevance_factor = 0.05*np.mean(N_k)\n",
        "    means = (post_probs.T @ speaker_features)/(N_k[:, np.newaxis])\n",
        "    means = np.nan_to_num(means, nan=0)\n",
        "    alpha_k = [[i/(i+relevance_factor)] for i in N_k]\n",
        "    alpha_k = np.array(alpha_k)\n",
        "    print(alpha_k)\n",
        "    ubm_means = ubm_gmm.get_means()\n",
        "    new_means = ubm_means + alpha_k*(means - ubm_means)\n",
        "    adapted_gmm = GMM(20)\n",
        "    adapted_gmm._init_params(speaker_features, new_means, ubm_gmm.get_covariances(), ubm_gmm.get_weights())\n",
        "\n",
        "    return adapted_gmm\n",
        "\n",
        "\n",
        "speaker_gmms = []\n",
        "for label in set(train_labels):\n",
        "    speaker_features = [feat for feat, lbl in zip(train_features, train_labels) if lbl == label]\n",
        "    speaker_features = np.concatenate(speaker_features)\n",
        "    adapted_gmm = map_adaptation(ubm_gmm, speaker_features)\n",
        "    speaker_gmms.append(adapted_gmm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivB11-qV_H86"
      },
      "outputs": [],
      "source": [
        "def identify_speaker(gmms, test_feature):\n",
        "    speaker_scores = np.array([gmm.score(test_feature) for gmm in gmms])\n",
        "    ubm_scores = ubm_gmm.score(test_feature)\n",
        "    scores = (speaker_scores - ubm_scores)\n",
        "    return np.argmax(scores)\n",
        "\n",
        "predictions = [identify_speaker(speaker_gmms, test_feature) for test_feature in test_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OITWNxSAEJh6",
        "outputId": "9b54b2c1-61d7-48d7-da3f-49260c1fa7a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 16, 9, 4, 17, 4, 1, 8, 7, 18, 19, 7, 18, 9, 13, 1, 5, 11, 13, 10, 9, 2, 14, 0, 0, 13, 18, 9]\n",
            "[0, 16, 9, 2, 17, 4, 1, 8, 7, 18, 19, 7, 18, 9, 13, 1, 6, 11, 13, 10, 9, 2, 14, 0, 0, 7, 18, 13]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4WauEZenVXy",
        "outputId": "900a8756-85c5-49d6-b157-88d4045603e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  85.71428571428571\n",
            "Confusion Matrix: \n",
            " [[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "print(\"Accuracy: \", accuracy*100)\n",
        "print(\"Confusion Matrix: \\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irX00bZYOol4",
        "outputId": "1cbae5d3-ac22-4b85-ac5a-69811e166a32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-6.23018921e+02,  4.53085846e+02, -1.87472122e+02, ...,\n",
              "         9.00942032e-05, -3.58281765e-04, -2.32152940e-04],\n",
              "       [-5.51705994e+02,  5.65153381e+02, -2.36920883e+02, ...,\n",
              "         3.05704307e-04,  8.71633890e-03, -1.42788527e-04],\n",
              "       [-5.28438171e+02,  5.88512878e+02, -2.14429092e+02, ...,\n",
              "         4.63694858e-04,  4.09147238e-03, -2.28414597e-04],\n",
              "       ...,\n",
              "       [-5.93146545e+02,  6.18139465e+02, -1.77309097e+02, ...,\n",
              "         1.06757303e-04, -1.46520083e-06,  5.16698929e-07],\n",
              "       [-6.60111877e+02,  6.44647705e+02, -2.27034882e+02, ...,\n",
              "         1.45346465e-04,  1.08848578e-06, -6.90398218e-07],\n",
              "       [-6.75001953e+02,  6.17803772e+02, -2.55973633e+02, ...,\n",
              "         2.89551332e-04, -8.51298595e-08,  1.74868881e-07]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "speaker_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYTvFi3SYzzy",
        "outputId": "fad52736-8946-4582-fbc4-c6dbf8fb48b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_super_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcxvAfcXN4Uk"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.decomposition import FactorAnalysis\n",
        "\n",
        "# # Function to compute supervectors for each speaker (Replace this with your supervector extraction method)\n",
        "\n",
        "\n",
        "# # Dummy data for demonstration (Replace this with your actual speech data)\n",
        "# # speech_data should be a list where each element corresponds to a speaker's speech data\n",
        "\n",
        "\n",
        "# # Perform TVS using Factor Analysis\n",
        "# num_components = 50 # You can set the desired number of components for the TVS\n",
        "# tvs = FactorAnalysis(n_components=num_components)\n",
        "# tvs.fit(train_super_vectors)\n",
        "\n",
        "# # Get the TV matrix\n",
        "# tvs_matrix = tvs.components_\n",
        "\n",
        "# # Each row of tvs_matrix represents a factor that defines the variation in the supervectors.\n",
        "\n",
        "# # Now you can use this TV matrix to transform new supervectors for unseen speakers.\n",
        "# # For example, if you have a new supervector for a speaker:\n",
        "# train_transform_vectors=[]\n",
        "# for i in train_super_vectors:\n",
        "#   train_transform_vectors.append(tvs.transform([i])[0])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRTUlxPYI3eq",
        "outputId": "e086b3ce-291b-4918-a1d8-b72b750fa24e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_super_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubDyAIb3IRyC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TVS:\n",
        "    def __init__(self, num_components):\n",
        "        self.num_components = num_components\n",
        "        self.transform_matrix = None\n",
        "\n",
        "    def fit_transform(self, supervectors):\n",
        "        # Convert list of supervectors to a 2D numpy array\n",
        "        supervectors = np.array(supervectors)\n",
        "\n",
        "        # Compute the mean supervector\n",
        "        mean_supervector = np.mean(supervectors, axis=0, keepdims=True)\n",
        "\n",
        "        # Center the supervectors\n",
        "        centered_supervectors = supervectors - mean_supervector\n",
        "\n",
        "        # Compute the supervector covariance matrix\n",
        "        covariance_matrix = np.cov(centered_supervectors, rowvar=False)\n",
        "\n",
        "        # Perform eigenvalue decomposition on the covariance matrix\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "        # Sort eigenvalues and eigenvectors in descending order\n",
        "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "        sorted_eigenvalues = eigenvalues[sorted_indices]\n",
        "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "        # Select the top 'num_components' eigenvectors\n",
        "        self.transform_matrix = sorted_eigenvectors[:, :self.num_components]\n",
        "\n",
        "        # Transform the supervectors to TVS space\n",
        "        transformed_supervectors = centered_supervectors.dot(self.transform_matrix)\n",
        "\n",
        "        return transformed_supervectors\n",
        "\n",
        "    def transform(self, supervectors):\n",
        "        # Check if the transform matrix is available\n",
        "        if self.transform_matrix is None:\n",
        "            raise ValueError(\"TVS not fitted. Please call fit_transform first.\")\n",
        "\n",
        "        # Convert list of supervectors to a 2D numpy array\n",
        "        supervectors = np.array(supervectors)\n",
        "\n",
        "        # Center the supervectors using the previously computed mean supervector\n",
        "        centered_supervectors = supervectors - np.mean(supervectors, axis=0, keepdims=True)\n",
        "\n",
        "        # Transform the centered supervectors to TVS space\n",
        "        transformed_supervectors = centered_supervectors.dot(self.transform_matrix)\n",
        "\n",
        "        return transformed_supervectors\n",
        "\n",
        "# Dummy data for illustration (Replace this with your actual speech data)\n",
        "# Each element of 'supervectors' list should be a 1D array representing a supervector\n",
        "supervectors = [np.random.randn(50) for _ in range(5)]  # 5 speakers with 50-dimensional supervectors each\n",
        "\n",
        "# Create a TVS instance and fit_transform the supervectors\n",
        "num_components = 50  # You can set the desired number of components for the TVS\n",
        "tvs = TVS(num_components)\n",
        "transformed_supervectors = tvs.fit_transform(train_super_vectors)\n",
        "\n",
        "# Now you can use the transformed supervectors for further processing or speaker verification tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHzDIVcMUl1C"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# # Dummy data for illustration (Replace this with your actual speaker data)\n",
        "# # X should be a numpy array of shape (num_samples, num_features) where num_samples is the number of supervectors\n",
        "# # and num_features is the dimensionality of each supervector.\n",
        "# X = train_transform_vectors # Assuming 100 supervectors with 840 features each\n",
        "# y = train_labels  # Assuming 5 different classes (speakers)\n",
        "\n",
        "# # Perform LDA with desired number of components\n",
        "# num_components = 10  # You can choose the desired number of components (smaller than the number of classes)\n",
        "# lda = LinearDiscriminantAnalysis(n_components=num_components)\n",
        "# X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "# # X_lda will be the transformed data with reduced dimensionality based on the LDA analysis.\n",
        "\n",
        "# # Now you can use the transformed data for further tasks, such as speaker recognition or classification.\n",
        "# # For example, you can use the transformed data for training a classifier like SVM or k-NN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc782hxjKQ3-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Dummy data for illustration (Replace this with your actual speaker data)\n",
        "# X should be a numpy array of shape (num_samples, num_features) where num_samples is the number of supervectors\n",
        "# and num_features is the dimensionality of each supervector.\n",
        "X = transformed_supervectors # Assuming 100 supervectors with 840 features each\n",
        "y = train_labels  # Assuming 5 different classes (speakers)\n",
        "\n",
        "# Perform LDA with desired number of components\n",
        "num_components = 10  # You can choose the desired number of components (smaller than the number of classes)\n",
        "lda = LinearDiscriminantAnalysis(n_components=num_components)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "# X_lda will be the transformed data with reduced dimensionality based on the LDA analysis.\n",
        "\n",
        "# Now you can use the transformed data for further tasks, such as speaker recognition or classification.\n",
        "# For example, you can use the transformed data for training a classifier like SVM or k-NN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4sPVxgjAQSY"
      },
      "outputs": [],
      "source": [
        "class LDA():\n",
        "  def __init__(self, num_components):\n",
        "    self.num_components = num_components\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    class_mean_vectors = []\n",
        "    for label in np.unique(y):\n",
        "        class_mean_vectors.append(np.mean(X[y == label], axis=0))\n",
        "    class_mean_vectors = np.array(class_mean_vectors)\n",
        "    within_class_scatter_matrix = np.zeros((X.shape[1], X.shape[1]))\n",
        "\n",
        "    for label in np.unique(y):\n",
        "        class_indices = np.where(y == label)[0]\n",
        "        class_scatter_matrix = np.cov(X[class_indices].T)\n",
        "        within_class_scatter_matrix += class_scatter_matrix\n",
        "\n",
        "    for i in range(within_class_scatter_matrix.shape[0]):\n",
        "      within_class_scatter_matrix[i, i] += 1e-3\n",
        "\n",
        "    overall_mean_vector = np.mean(X, axis=0)\n",
        "    between_class_scatter_matrix = np.zeros((X.shape[1], X.shape[1]))\n",
        "    for i, class_mean in enumerate(class_mean_vectors):\n",
        "        n_samples = X[y == i].shape[0]\n",
        "        between_class_scatter_matrix += n_samples * np.outer((class_mean - overall_mean_vector), (class_mean - overall_mean_vector))\n",
        "\n",
        "    matrix_product = np.dot(np.linalg.inv(within_class_scatter_matrix), between_class_scatter_matrix)\n",
        "    eig_vals, eig_vecs = np.linalg.eig(matrix_product)\n",
        "    sorted_indices = np.argsort(eig_vals)[::-1]\n",
        "    sorted_eig_vals = eig_vals[sorted_indices]\n",
        "    sorted_eig_vecs = eig_vecs[:,sorted_indices]\n",
        "\n",
        "    self.transform_matrix = sorted_eig_vecs[:,:self.num_components]\n",
        "\n",
        "  def transform(self, X):\n",
        "    X_lda = np.dot(X, self.transform_matrix)\n",
        "    return X_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMywPAFHHq6b"
      },
      "outputs": [],
      "source": [
        "# X = transformed_supervectors # Assuming 100 supervectors with 840 features each\n",
        "# y = train_labels  # Assuming 5 different classes (speakers)\n",
        "\n",
        "# # Perform LDA with desired number of components\n",
        "# num_components = 10  # You can choose the desired number of components (smaller than the number of classes)\n",
        "# lda = LDA(num_components)\n",
        "# lda.fit(X, y)\n",
        "# X_lda = lda.transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZT1M8ooz6ad",
        "outputId": "ae9c7abd-1b60-4d35-9bb7-5b93bd780cd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(X_lda[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcpTjfLKgvkB"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# # Dummy data for illustration (Replace this with your actual speaker data)\n",
        "# # X should be a numpy array of shape (num_samples, num_features) where num_samples is the number of supervectors\n",
        "# # and num_features is the dimensionality of each supervector.\n",
        "# X = train_super_vectors # Assuming 100 supervectors with 840 features each\n",
        "# y = train_labels  # Assuming 5 different classes (speakers)\n",
        "\n",
        "# # Perform LDA with desired number of components\n",
        "# num_components = 10  # You can choose the desired number of components (smaller than the number of classes)\n",
        "# lda = LinearDiscriminantAnalysis(n_components=num_components)\n",
        "# X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "# # X_lda will be the transformed data with reduced dimensionality based on the LDA analysis.\n",
        "\n",
        "# # Now you can use the transformed data for further tasks, such as speaker recognition or classification.\n",
        "# # For example, you can use the transformed data for training a classifier like SVM or k-NN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EtGiVs9c_wR"
      },
      "outputs": [],
      "source": [
        "# claim_vectors=[]\n",
        "# for label in set(train_labels):\n",
        "#     speaker_feature_super_vector=get_super_vector(ubm_gmm,speaker_features)\n",
        "#     tvs_features=tvs.transform([speaker_feature_super_vector])\n",
        "#     claim_vectors.append(lda.transform(tvs_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1H2twA-XeyD"
      },
      "outputs": [],
      "source": [
        "# claim_vectors=[]\n",
        "# for label in set(train_labels):\n",
        "#     speaker_features = [feat for feat, lbl in zip(train_features, train_labels) if lbl == label]\n",
        "#     speaker_features = np.concatenate(speaker_features)\n",
        "#     speaker_feature_super_vector=get_super_vector(ubm_gmm,speaker_features)\n",
        "#     tvs_features=tvs.transform([speaker_feature_super_vector)\n",
        "#     claim_vectors.append(lda.transform(tvs_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-nnzPI_c9Ua"
      },
      "outputs": [],
      "source": [
        "test_super_vectors=[]\n",
        "for feature in test_features:\n",
        "  test_speaker_feature_super_vector=get_super_vector(ubm_gmm,feature)\n",
        "  test_super_vectors.append(test_speaker_feature_super_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SWhtOJJZRVK"
      },
      "outputs": [],
      "source": [
        "test_vectors=[]\n",
        "transformed_test_supervectors=tvs.transform(test_super_vectors)\n",
        "for feature in transformed_test_supervectors:\n",
        "  test_vectors.append(lda.transform([feature])[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xJXMqUXKymT",
        "outputId": "3f96223f-a4cf-4bfd-814a-0a5174c1d1ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(test_vectors[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spgBVaks0OSO",
        "outputId": "0a6a5e42-51c7-4f20-f469-c5c1eaafd4f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-5.58626815, -4.74554822, -2.31316677, -1.14749552,  0.82678825,\n",
              "        1.11439636,  0.25501306, -0.68276513,  4.26039574,  0.83775426])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(test_vectors[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ucxWxiM2dFf",
        "outputId": "33bf1272-71a2-4735-f4ee-39b77d3b6ef0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12.78918652, -4.05922756, -1.36915298, -2.58332096, -6.08958021,\n",
              "       -0.87106843, -7.629604  , -3.7611331 ,  1.29795279, -0.02541987])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(X_lda[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6klbtgdhNLC"
      },
      "outputs": [],
      "source": [
        "# test_vectors=[]\n",
        "# for feature in test_features:\n",
        "#   test_speaker_feature_super_vector=get_super_vector(ubm_gmm,feature)\n",
        "#   test_vectors.append(lda.transform([test_speaker_feature_super_vector]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPrMBe0Klbdv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovEIti_NnGHS",
        "outputId": "10698abc-a9ff-491c-fad0-2e47fbedfb83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-1364c02f19e8>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  posteriors = likelihoods/np.sum(likelihoods, axis=1, keepdims= True)\n"
          ]
        }
      ],
      "source": [
        "train_super_vectors = []\n",
        "test_super_vectors = []\n",
        "for feature in train_features:\n",
        "  train_super_vectors.append(get_super_vector(ubm_gmm, feature))\n",
        "for feature in test_features:\n",
        "  test_super_vectors.append(get_super_vector(ubm_gmm, feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVeXlwtHmYQ-",
        "outputId": "d366a17e-75dd-4592-b339-ddc8dedc8225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-5.49201590e+02  5.67159921e+02 -4.04128506e+02  3.80113514e+01\n",
            "  1.33943010e+02 -4.12435886e+02 -1.34666657e+02 -1.07361075e+02\n",
            " -3.52079790e+02 -5.18476894e+00 -1.13543549e+02 -2.61566043e+02\n",
            "  4.03756642e+01  0.00000000e+00 -4.44451719e+02  2.07816308e+04\n",
            "  1.86234053e+04 -2.41734577e+04 -2.85304516e+04  1.06782705e+04]\n"
          ]
        }
      ],
      "source": [
        "print(train_super_vectors[0][:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W42x6wBQmw1E",
        "outputId": "7924d492-28d6-4d0f-b159-75f97fa90f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-5.49877649e+02  5.67089266e+02 -4.03761138e+02  3.91424251e+01\n",
            "  1.34869061e+02 -4.12218690e+02 -1.34334034e+02 -1.07864841e+02\n",
            " -3.53501427e+02 -5.89195150e+00 -1.13807981e+02 -2.62289011e+02\n",
            "  3.94676601e+01  0.00000000e+00 -4.47898282e+02  2.07825522e+04\n",
            "  1.86213581e+04 -2.41339366e+04 -2.84869989e+04  1.06861753e+04]\n"
          ]
        }
      ],
      "source": [
        "print(test_super_vectors[0][:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EggGQUv-aFKn"
      },
      "outputs": [],
      "source": [
        "predictions=[]\n",
        "for test in test_vectors:\n",
        "  ind_scores=[]\n",
        "  for x in X_lda:\n",
        "    ind_scores.append(mean_squared_error(x,test))\n",
        "  #print(ind_scores)\n",
        "  scores=[]\n",
        "  for label in set(train_labels):\n",
        "   speaker_scores = [feat for feat, lbl in zip(ind_scores, train_labels) if lbl == label]\n",
        "   scores.append(sum(speaker_scores))\n",
        "  #print(len(ind_scores), len(scores))\n",
        "  #print(scores)\n",
        "  min_index = scores.index(min(scores))\n",
        "  predictions.append(min_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl2kDC93xpmH"
      },
      "outputs": [],
      "source": [
        "predictions=[]\n",
        "for test in test_super_vectors:\n",
        "  ind_scores=[]\n",
        "  for x in train_super_vectors:\n",
        "    ind_scores.append(mean_squared_error(x,test))\n",
        "  # print(ind_scores)\n",
        "  scores=[]\n",
        "  for label in set(train_labels):\n",
        "   speaker_scores = [feat for feat, lbl in zip(ind_scores, train_labels) if lbl == label]\n",
        "   scores.append(sum(speaker_scores))\n",
        "  # print(len(ind_scores), len(scores))\n",
        "  # print(scores)\n",
        "  min_index = scores.index(min(scores))\n",
        "  predictions.append(min_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXH8ccHzkP2m",
        "outputId": "a165c680-8b8f-4b58-fd88-12d857c2aab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 16, 13, 2, 17, 4, 1, 8, 7, 9, 13, 7, 18, 9, 13, 1, 6, 11, 13, 10, 9, 2, 14, 0, 0, 13, 18, 13]\n",
            "[0, 16, 9, 2, 17, 4, 1, 8, 7, 18, 19, 7, 18, 9, 13, 1, 6, 11, 13, 10, 9, 2, 14, 0, 0, 7, 18, 13]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22XWBHc7b6d1",
        "outputId": "13a7368d-1051-466b-be67-d7b5b0178e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  85.71428571428571\n",
            "Confusion Matrix: \n",
            " [[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "conf_matrix = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "print(\"Accuracy: \", accuracy*100)\n",
        "print(\"Confusion Matrix: \\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VIWxSfucG94"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}